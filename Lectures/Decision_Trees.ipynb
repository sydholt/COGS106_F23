{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Decision Trees \n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Let's do a high-level recap of what we've learned in this course so far:\n",
    "\n",
    "Say we have input data $X = (X_1, X_2, ..., X_n)$ and corresponding class labels $Y = (Y_1, Y_2, ..., Y_n)$ where $n$ represents the number of observations/instances (i.e., unique samples). Much of statistical learning concerns trying to model this relationship between our data's $X$ and $Y$. In particular, we assert that the $Y$'s were produced/generated by some underlying function $f(X)$, and that there is inevitably some noise and systematic, implicit bias and error $\\epsilon$ that cannot be captured by any $f(X)$. Thus, we have:\n",
    "\n",
    "$Y = f(X) + \\epsilon$\n",
    "\n",
    "Its important to remember that most of the time (and certainly in this class) X is often times a vector in a multi-dimensional space, because we are collecting a lot of data. This has advantages, because more features usually means better prediction.  \n",
    "\n",
    "If you are working with labels $Y$, and you make use of them for your modelling, then you are working on a **supervised** learning task. If you do not have or make use of $Y$ values, and you are only concerned with the input data $X$, you are working on an **unsupervised** learning task.  I hope to talk about this next week, as it may be helpful in your class projects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling data concerns either **prediction** or **inference**:\n",
    "\n",
    "**Prediction:** concerns trying to learn a function $\\hat{f}(X)$ that is as close as possible to the true function $f(X)$. This allows us to estimate $Y$ values for any new input data $X$.\n",
    "*   This is what you are doing this week with Logistic Regression models to predict heart disease (the labels). \n",
    "\n",
    "**Inference:** concerns trying to understand/model the _relationship_ between $X$ and $Y$, effectively learning how the data was generated.  \n",
    "*   This is what we did when we fit different parameters of the shifted Wald distribution to response time data that came from different experimental conditions (the labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if our data looked like this? \n",
    "\n",
    "![](images/complex.png)\n",
    "\n",
    "### We could develop complicated models (e.g., deep learning neural networks to solve the problem of separating the two classes of data)\n",
    "### It would be desirable to build models of data that allow for complex decision boundaries while maintaining intepretability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a decision tree?  \n",
    "\n",
    "### At its heart, a decision tree is a flow chart. \n",
    "\n",
    "### Formally, a decision tree model is one in which the final outcome of the model is based on a series of comparisons of the values of predictors against threshold values.\n",
    "### In a graphical representation (flow chart),\n",
    "* ### the internal nodes of the tree represent attribute testing.\n",
    "* ### branching in the next level is determined by attribute value.\n",
    "* ### terminal leaf nodes represent class assignments.\n",
    "\n",
    "![](images/orangelemon.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlike Logistic Regression, which makes lines of arbitrary orientation, in a decision tree every flow chart tree corresponds to a partition of the feature space by axis aligned lines or (hyper) planes. Conversely, every such partition can be written as a flow chart tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a training set, learning a decision tree model for binary classification means:\n",
    "* ###  producing an optimal partition of the feature space with axis-aligned linear boundaries (maximally interpretable!),\n",
    "* ### each region is predicted to have a class label based on the largest count of the training points in that region. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### My goal is for none of the topics we learn in this class to seem like nebulus concepts or black-boxes of magic. In this course, it's important to understand the models that you can use to help you with your data, and this includes not only knowing how to invoke these as tools within Python libraries but to have an understanding of what each model is actually doing 'under the hood' -- how it actually works -- as this provides insights into how to interpret the model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the play_tennis data set \n",
    "tennis_df = pd.read_csv(\"data/play_tennis.csv\")\n",
    "tennis_df.info()\n",
    "tennis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_num = tennis_df\n",
    "tennis_num = pd.get_dummies(tennis_num, columns=['outlook', 'temp', 'humidity', 'windy'])\n",
    "tennis_num.info()\n",
    "tennis_num.head()\n",
    "\n",
    "class_names   = ['No','Yes']\n",
    "feature_names = tennis_num.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate our data into X and Y portions\n",
    "x_train = tennis_num.iloc[:, tennis_num.columns != 'play'].values\n",
    "y_train = tennis_num['play'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build a DecisionTree classifier as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "tree_vis = plot_tree(dt, filled=True, feature_names = feature_names, class_names = class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal here is to make splits that will create pure as possible regions of the feature space.  The Gini coefficient is a statistical measure of how \"pure\" a class is.  The goal of a decision tree is to partition the data into pure classes with gini = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we did not use the tree to do any classification. Our data was too small to consider such.\n",
    "\n",
    "### Let's revisit the PIMA Indians diabetes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "pima = pd.read_csv(\"data/diabetes.csv\")\n",
    "pima.info()\n",
    "cols = pima.columns\n",
    "diabetes = pima['Outcome']\n",
    "predictors = pima[cols[1:8]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate out the data we need\n",
    "X             = np.array(predictors)\n",
    "y             = diabetes\n",
    "class_names   = class_names=['Undiagnosed','Diabetes']\n",
    "feature_names = cols[1:8]\n",
    "\n",
    "# perform a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit a decision tree classifier with max_depth=2\n",
    "dt_pima = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "dt_pima.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "plot_tree(dt_pima, filled=True, feature_names = feature_names, class_names = class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision - What proportion of postive identifications were actually correct\n",
    "###  \n",
    "### TP = True Positive\n",
    "### FP = False Positive\n",
    "### TN - True Negative \n",
    "### FN - False Negative\n",
    "### Accuracy - what fraction did you get right \n",
    "### $$ Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$  \n",
    "### Precision - what fraction of the positives were labeled correctly?\n",
    "### $$ Precision = \\frac{TP}{TP+FP}$$\n",
    "### Recall - What proportion of actual positive was identified correctly? \n",
    "### $$ Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt_pima.predict(X_test)\n",
    "print('accuracy score: %.2f' % accuracy_score(y_test,y_pred))\n",
    "print('precision score: %.2f' % precision_score(y_test,y_pred))\n",
    "print('recall score: %.2f' % recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"jet\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.xticks(tick_marks+0.5, class_names)\n",
    "plt.yticks(tick_marks+0.5, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pprob = dt_pima.predict_proba(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pprob[:,1])\n",
    "auc = roc_auc_score(y_test, y_pprob[:,1])\n",
    "plt.plot(fpr,tpr,label=\"DecisionTree Pima, auc=\"+str(auc))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0,1],[0,1],'k-')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
